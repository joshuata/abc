/* This header file contains useful helper functions for manipulating
 * the CIVL versions of various Cuda objects.
 */

#ifndef __CUDA_HELPER
#define __CUDA_HELPER

#include <concurrency.cvh>

/* used to represent the size of three dimensional grids
 */
typedef struct {
  unsigned int x, y, z;
} dim3;

/* used to represent a location in a three dimensional grid
 */
typedef struct {
  unsigned int x, y, z;
} uint3;

/* a flag type used to indicate the type of memory transfer to occur
 * in a call to cudaMemcpy
 */
enum cudaMemcpyKind {
  cudaMemcpyHostToHost,
  cudaMemcpyHostToDevice,
  cudaMemcpyDeviceToHost,
  cudaMemcpyDeviceToDevice,
  cudaMemcpyDefault
};

/* the type returned by all Cuda functions
 */
enum cudaError {
  cudaSuccess,
  cudaErrorMissingConfiguration,
  cudaErrorMemoryAllocation,
  cudaErrorInitializationError,
  cudaErrorLaunchFailure,
  cudaErrorPriorLaunchFailure,
  cudaErrorLaunchTimeout,
  cudaErrorLaunchOutOfResources,
  cudaErrorInvalidDeviceFunction,
  cudaErrorInvalidConfiguration,
  cudaErrorInvalidDevice,
  cudaErrorInvalidValue,
  cudaErrorInvalidPitchValue,
  cudaErrorInvalidSymbol,
  cudaErrorMapBufferObjectFailed,
  cudaErrorUnmapBufferObjectFailed,
  cudaErrorInvalidHostPointer,
  cudaErrorInvalidDevicePointer,
  cudaErrorInvalidTexture,
  cudaErrorInvalidTextureBinding,
  cudaErrorInvalidChannelDescriptor,
  cudaErrorInvalidMemcpyDirection,
  cudaErrorAddressOfConstant,
  cudaErrorTextureFetchFailed,
  cudaErrorTextureNotBound,
  cudaErrorSynchronizationError,
  cudaErrorInvalidFilterSetting,
  cudaErrorInvalidNormSetting,
  cudaErrorMixedDeviceExecution,
  cudaErrorCudartUnloading,
  cudaErrorUnknown,
  cudaErrorNotYetImplemented,
  cudaErrorMemoryValueTooLarge,
  cudaErrorInvalidResourceHandle,
  cudaErrorNotReady,
  cudaErrorInsufficientDriver,
  cudaErrorSetOnActiveProcess,
  cudaErrorInvalidSurface,
  cudaErrorNoDevice,
  cudaErrorECCUncorrectable,
  cudaErrorSharedObjectSymbolNotFound,
  cudaErrorSharedObjectInitFailed,
  cudaErrorUnsupportedLimit,
  cudaErrorDuplicateVariableName,
  cudaErrorDuplicateTextureName,
  cudaErrorDuplicateSurfaceName,
  cudaErrorDevicesUnavailable,
  cudaErrorInvalidKernelImage,
  cudaErrorNoKernelImageForDevice,
  cudaErrorIncompatibleDriverContext,
  cudaErrorPeerAccessAlreadyEnabled,
  cudaErrorPeerAccessNotEnabled,
  cudaErrorDeviceAlreadyInUse,
  cudaErrorProfilerDisabled,
  cudaErrorProfilerNotInitialized,
  cudaErrorProfilerAlreadyStarted,
  cudaErrorProfilerAlreadyStopped,
  cudaErrorAssert,
  cudaErrorTooManyPeers,
  cudaErrorHostMemoryAlreadyRegistered,
  cudaErrorHostMemoryNotRegistered,
  cudaErrorOperatingSystem,
  cudaErrorStartupFailure,
  cudaErrorApiFailureBase
};
typedef enum cudaError cudaError_t;

/* struct representing the properties of a Cuda device
 */
typedef struct cudaDeviceProp {
  char name[256];
  size_t totalGlobalMem;
  size_t sharedMemPerBlock;
  int regsPerBlock;
  int warpSize;
  size_t memPitch;
  int maxThreadsPerBlock;
  int maxThreadsDim[3];
  int maxGridSize[3];
  int clockRate;
  size_t totalConstMem;
  int major;
  int minor;
  size_t textureAlignment;
  size_t texturePitchAlignment;
  int deviceOverlap;
  int multiProcessorCount;
  int kernelExecTimeoutEnabled;
  int integrated;
  int canMapHostMemory;
  int computeMode;
  int maxTexture1D;
  int maxTexture1DLinear;
  int maxTexture2D[2];
  int maxTexture2DLinear[3];
  int maxTexture2DGather[2];
  int maxTexture3D[3];
  int maxTextureCubemap;
  int maxTexture1DLayered[2];
  int maxTexture2DLayered[3];
  int maxTextureCubemapLayered[2];
  int maxSurface1D;
  int maxSurface2D[2];
  int maxSurface3D[3];
  int maxSurface1DLayered[2];
  int maxSurface2DLayered[3];
  int maxSurfaceCubemap;
  int maxSurfaceCubemapLayered[2];
  size_t surfaceAlignment;
  int concurrentKernels;
  int ECCEnabled;
  int pciBusID;
  int pciDeviceID;
  int pciDomainID;
  int tccDriver;
  int asyncEngineCount;
  int unifiedAddressing;
  int memoryClockRate;
  int memoryBusWidth;
  int l2CacheSize;
  int maxThreadsPerMultiProcessor;
} cudaDeviceProp;

/* flag type used to represent the status of a kernel instance
 */
typedef enum _kernelStatus {
    _kernelStatusWaiting,
    _kernelStatusRunning,
    _kernelStatusFinished
} _kernelStatus;

/* type used to represent an instance of a Cuda kernel
 */
typedef struct _kernelInstance _kernelInstance;

_kernelStatus getStatus(_kernelInstance*);

/* a type that wraps a kernel instance for insertion into a list
 */
typedef struct _kernelInstanceNode _kernelInstanceNode;

/* _kernelInstanceNode interface
 */
_kernelInstance *getInstance(_kernelInstanceNode*);

/* a type used to represent a Cuda stream
 */
typedef struct _CUstream _CUstream;
typedef _CUstream* cudaStream_t;

/* _CUstream interface
 */
_kernelInstanceNode *getMostRecent(cudaStream_t);

_Bool isUsable(cudaStream_t);

void setUsable(cudaStream_t, _Bool);

/* a type that wraps a stream for insertion into a list
 */
typedef struct _cudaStreamNode _cudaStreamNode;

/* _cudaStreamNode interface
 */
void setStream(_cudaStreamNode*, cudaStream_t);

void setNext(_cudaStreamNode*, _cudaStreamNode*);

/* a type used to represent a Cuda event
 */
typedef struct _CUevent _CUevent;
typedef _CUevent* cudaEvent_t;

/* _CUevent interface
 */
_kernelInstance **getInstances(cudaEvent_t);

void setInstances(cudaEvent_t, _kernelInstance**, int);

int getNumInstances(cudaEvent_t);


/* a type representing the state of a Cuda device
 */
typedef struct _cudaContext _cudaContext;

/* _cudaContext interface
 */
int getNumStreams(_cudaContext*);

_cudaStreamNode *getHeadNode(_cudaContext*);

cudaStream_t getNullStream(_cudaContext*);

void addNewStream(_cudaContext*, _cudaStreamNode*);


/* Computes the one dimensional index of a grid cell at a given location
 * in a three dimensional grid of a given size
 */
int _index (dim3 size, uint3 location);

/* Lifts a single integer x into a three dimensional vector representing
 * a one dimensional grid of length x
 */
dim3 _toDim3(int x);

/* Given a three dimensional vector representing a grid of size dim,
 * create and destroy a process, in parallel, for each cell in the grid. 
 * The location of the cell is passed to the spawning function.
 */
void _runProcs(dim3 dim, void spawningFunction(uint3));

// ------------------------------------------------

/* $wait on a given process is it is non-null
 */
void _tryWait($proc p);

/* The current state of the GPU
 */
_cudaContext _context;

/* malloc and initialize a new _kernelInstance
 */
_kernelInstance *_kernelInstanceCreate(void);

/* cleanup and free a given _kernelInstance
 */
void _kernelInstanceDestroy(_kernelInstance *i);

/* malloc and initialize a new _kernelInstanceNode
 */
_kernelInstanceNode *_kernelInstanceNodeCreate(void);

/* cleanup and free a given _kernelInstanceNode
 */
void _kernelInstanceNodeDestroy(_kernelInstanceNode *node);

/* malloc and initialize a new stream
 */
cudaStream_t _streamCreate(void);

/* block until the most recently enqueued process on the given stream
 * has terminated (meaning all kernels in that stream have completed)
 */
void _streamWait(cudaStream_t s);

/* block until no more streams have kernels executing
 */
void _streamWaitAll(void);

/* cleanup and free a given stream
 */
void _streamDestroy(cudaStream_t s);

/* malloc and initialize a new _cudaStreamNode
 */
_cudaStreamNode *_streamNodeCreate(void);

/* cleanup and free a given _cudaStreamNode
 */
void _streamNodeDestroy(_cudaStreamNode *node);

/* destroy all stream nodes contained in the context
 */
void _streamNodeDestroyAll(void);

/* malloc and initialize a new event
 */
cudaEvent_t _eventCreate(void);

/* block until all _kernelInstances contained in this event have
 * completed
 */
void _eventWait(cudaEvent_t e);

/* cleanup and free a given event
 */
void _eventDestroy(cudaEvent_t e);

/* initialize the cuda context. must be called before any cuda functions.
 */
void _cudaInit(void);

/* cleanup the cuda context. must be called after all cuda functions.
 */
void _cudaFinalize(void);

/* returns an array of pointers to the most recently enqueued kernel
 * of each stream.
 */
_kernelInstance **_allMostRecentKernels(void);

/* create a kernel instance for the given function k, and enqueue it
 * onto the given stream.
 */
void _enqueueKernel(cudaStream_t stream, void (*k)(_kernelInstance*, cudaEvent_t));

/* called by kernel processes. wait on the given event, then update
 * the status of the calling kernel to indicate it has finished waiting
 */
void _waitInQueue (_kernelInstance *this, cudaEvent_t e);

/* called by kernel processes. update the status of the calling kernel
 * to indicate that it has completed execution
 */
void _kernelFinish(_kernelInstance *k);

#endif

